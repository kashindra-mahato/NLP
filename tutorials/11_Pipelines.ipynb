{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Oo2_F2jwsA8J",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Tutorial: How to Use Pipelines\n",
        "\n",
        "In this tutorial, you will learn how the `Pipeline` connects the different components in Haystack. Whether you are using a Reader, Summarizer\n",
        "or Retriever (or 2), the `Pipeline` class will help you build a Directed Acyclic Graph (DAG) that\n",
        "determines how to route the output of one component into the input of another.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "DwGR2m4MsA8K",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "## Preparing the Colab Environment\n",
        "\n",
        "- [Enable GPU Runtime](https://docs.haystack.deepset.ai/docs/enabling-gpu-acceleration#enabling-the-gpu-in-colab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd2rYyussA8K"
      },
      "source": [
        "## Installing Haystack\n",
        "\n",
        "To start, let's install the latest release of Haystack with `pip`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W4mAfAasA8L"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab,inference]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q-xTi6ksA8L"
      },
      "source": [
        "### Enabling Telemetry\n",
        "Knowing you're using this tutorial helps us decide where to invest our efforts to build a better product but you can always opt out by commenting the following line. See [Telemetry](https://docs.haystack.deepset.ai/docs/telemetry) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QadbeTutsA8L"
      },
      "outputs": [],
      "source": [
        "from haystack.telemetry import tutorial_running\n",
        "\n",
        "tutorial_running(11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "CwZDy9f-sA8M",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Logging\n",
        "\n",
        "We configure how logging messages should be displayed and which log level should be used before importing Haystack.\n",
        "Example log message:\n",
        "INFO - haystack.utils.preprocessing -  Converting data/tutorial1/218_Olenna_Tyrell.txt\n",
        "Default log level in basicConfig is WARNING so the explicit parameter is not necessary but can be changed easily:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YXK3IqDsA8M",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zceM4-j_sA8M"
      },
      "source": [
        "## Initializing the DocumentStore\n",
        "\n",
        "A DocumentStore stores the Documents that a system uses to retrieve or find answers to your questions. In this tutorial, you'll use the `InMemoryDocumentStore`.\n",
        "\n",
        "Let's initialize the DocumentStore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktcvOryoCudy"
      },
      "outputs": [],
      "source": [
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "\n",
        "document_store = InMemoryDocumentStore(use_bm25=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lDs0kKPmsA8N",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Fetching and Writing Documents\n",
        "\n",
        "Let's fetch the txt files (in this case, pages from the Game of Thrones wiki) and prepare them so that they can be indexed into the DocumentStore:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixIzMepqALK0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V80mCVopsA8N",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from haystack.utils import fetch_archive_from_http, convert_files_to_docs, clean_wiki_text\n",
        "\n",
        "# Download and prepare data - 517 Wikipedia articles for Game of Thrones\n",
        "doc_dir = \"data/tutorial11\"\n",
        "s3_url = \"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt11.zip\"\n",
        "fetch_archive_from_http(url=s3_url, output_dir=doc_dir)\n",
        "\n",
        "# convert files to dicts containing documents that can be indexed to our datastore\n",
        "got_docs = convert_files_to_docs(dir_path=doc_dir, clean_func=clean_wiki_text, split_paragraphs=True)\n",
        "document_store.delete_documents()\n",
        "document_store.write_documents(got_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYx9pJaXALK1"
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import BM25Retriever, EmbeddingRetriever, FARMReader\n",
        "\n",
        "bm25_retriever = BM25Retriever()\n",
        "\n",
        "from haystack.pipelines import DocumentSearchPipeline\n",
        "from haystack.utils import print_documents\n",
        "\n",
        "p_retrieval = DocumentSearchPipeline(bm25_retriever)\n",
        "# res = p_retrieval.run(query=\"Who is the father of Arya Stark?\", params={\"Retriever\": {\"top_k\": 10}})\n",
        "# print_documents(res, max_text_len=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "X79w6kHrsA8N",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Initializing Core Components\n",
        "\n",
        "Here we initialize the core components that we will be gluing together using the `Pipeline` class.\n",
        "Initialize a `BM25Retriever`, an `EmbeddingRetriever`, and a `FARMReader`.\n",
        "You can combine these components to create a classic Retriever-Reader pipeline that is designed\n",
        "to perform Open Domain Question Answering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJFkt1LVsA8N",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import BM25Retriever, EmbeddingRetriever, FARMReader\n",
        "\n",
        "# Initialize Sparse Retriever\n",
        "bm25_retriever = BM25Retriever(document_store=document_store)\n",
        "\n",
        "# Initialize embedding Retriever\n",
        "embedding_retriever = EmbeddingRetriever(\n",
        "    document_store=document_store, embedding_model=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
        ")\n",
        "document_store.update_embeddings(embedding_retriever, update_existing_embeddings=False)\n",
        "\n",
        "# Initialize Reader\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "RwqtQRoAsA8N",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Prebuilt Pipelines\n",
        "\n",
        "Haystack features many prebuilt pipelines that cover common tasks. The most used one is `ExtractiveQAPipeline`.\n",
        "Now, initialize the ExtractiveQAPipeline and run it with a query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZZ_Tt08sA8N",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "from haystack.utils import print_answers\n",
        "\n",
        "p_extractive_premade = ExtractiveQAPipeline(reader=reader, retriever=bm25_retriever)\n",
        "res = p_extractive_premade.run(\n",
        "    query=\"Who is the father of Arya Stark?\", params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
        ")\n",
        "print_answers(res, details=\"minimum\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "PqKe8Nw9sA8N"
      },
      "source": [
        "If you want to just do the retrieval step, you can use a DocumentSearchPipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA1DyIhLsA8N",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from haystack.pipelines import DocumentSearchPipeline\n",
        "from haystack.utils import print_documents\n",
        "\n",
        "p_retrieval = DocumentSearchPipeline(embedding_retriever)\n",
        "res = p_retrieval.run(query=\"Who is the father of Arya Stark?\", params={\"Retriever\": {\"top_k\": 10}})\n",
        "print_documents(res, max_text_len=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_ISxlB1zsA8N"
      },
      "source": [
        "Haystack features prebuilt pipelines to do:\n",
        "- document search (DocumentSearchPipeline),\n",
        "- document search with summarization (SearchSummarizationPipeline)\n",
        "- FAQ style QA (FAQPipeline)\n",
        "- translated search (TranslationWrapperPipeline)\n",
        "To find out more about these pipelines, have a look at our [documentation](https://docs.haystack.deepset.ai/docs/pipelines).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "YYLCqoYTsA8O",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Generating a Pipeline Diagram\n",
        "\n",
        "With any Pipeline, whether prebuilt or custom constructed,\n",
        "you can save a diagram showing how all the components are connected.\n",
        "\n",
        "![image](https://github.com/deepset-ai/haystack/blob/main/docs/img/retriever-reader-pipeline.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krDbpxY3sA8O",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment the following to generate the images\n",
        "# !apt install libgraphviz-dev\n",
        "# !pip install pygraphviz\n",
        "\n",
        "# p_extractive_premade.draw(\"pipeline_extractive_premade.png\")\n",
        "# p_retrieval.draw(\"pipeline_retrieval.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "RB9PEOKssA8O",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Custom Extractive QA Pipeline\n",
        "\n",
        "If you need a custom pipeline for your task or add extra nodes to a pipeline, you can create a pipeline from scratch instead of using a prebuilt one.\n",
        "\n",
        "Now, try to rebuild the ExtractiveQAPipeline using the generic Pipeline class.\n",
        "You can do this by adding the building blocks as shown in the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5WMGbCgsA8O",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from haystack.pipelines import Pipeline\n",
        "\n",
        "# Custom built extractive QA pipeline\n",
        "p_extractive = Pipeline()\n",
        "p_extractive.add_node(component=bm25_retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
        "p_extractive.add_node(component=reader, name=\"Reader\", inputs=[\"Retriever\"])\n",
        "\n",
        "# Now we can run it\n",
        "res = p_extractive.run(query=\"Who is the father of Arya Stark?\", params={\"Retriever\": {\"top_k\": 10}})\n",
        "print_answers(res, details=\"minimum\")\n",
        "\n",
        "# Uncomment the following to generate the pipeline image\n",
        "# p_extractive.draw(\"pipeline_extractive.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Z_R1488-sA8O",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Combining Retrievers Using a Custom Pipeline\n",
        "\n",
        "Pipelines offer a very simple way to ensemble together different components.\n",
        "In this example, you'll combine the power of an `EmbeddingRetriever`\n",
        "with the keyword based `BM25Retriever`.\n",
        "See our [documentation](https://docs.haystack.deepset.ai/docs/retriever#deeper-dive-vector-based-vs-keyword-based) to understand why\n",
        "you might want to combine a dense and sparse retriever.\n",
        "\n",
        "![image](https://github.com/deepset-ai/haystack/blob/main/docs/img/tutorial11_custompipelines_pipeline_ensemble.png?raw=true)\n",
        "\n",
        "Here you'll use a `JoinDocuments` node to merge the predictions from each retriever:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHY1iwlysA8O",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import JoinDocuments\n",
        "\n",
        "# Create ensembled pipeline\n",
        "p_ensemble = Pipeline()\n",
        "p_ensemble.add_node(component=bm25_retriever, name=\"BM25Retriever\", inputs=[\"Query\"])\n",
        "p_ensemble.add_node(component=embedding_retriever, name=\"EmbeddingRetriever\", inputs=[\"Query\"])\n",
        "p_ensemble.add_node(\n",
        "    component=JoinDocuments(join_mode=\"concatenate\"), name=\"JoinResults\", inputs=[\"BM25Retriever\", \"EmbeddingRetriever\"]\n",
        ")\n",
        "p_ensemble.add_node(component=reader, name=\"Reader\", inputs=[\"JoinResults\"])\n",
        "\n",
        "# Uncomment the following to generate the pipeline image\n",
        "# p_ensemble.draw(\"pipeline_ensemble.png\")\n",
        "\n",
        "# Run pipeline\n",
        "res = p_ensemble.run(\n",
        "    query=\"Who is the father of Arya Stark?\", params={\"EmbeddingRetriever\": {\"top_k\": 5}, \"BM25Retriever\": {\"top_k\": 5}}\n",
        ")\n",
        "print_answers(res, details=\"minimum\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Z2_Sonx6sA8O",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Custom Nodes\n",
        "\n",
        "Nodes are relatively simple objects\n",
        "and we encourage our users to design their own if they don't see one that fits their use case\n",
        "\n",
        "The only requirements are:\n",
        "- Create a class that inherits `BaseComponent`.\n",
        "- Add a method run() to your class. Add the mandatory and optional arguments it needs to process. These arguments must be passed as input to the pipeline, inside `params`, or output by preceding nodes.\n",
        "- Add processing logic inside the run() (e.g. reformatting the query).\n",
        "- Return a tuple that contains your output data (for the next node)\n",
        "and the name of the outgoing edge (by default \"output_1\" for nodes that have one output)\n",
        "- Add a class attribute outgoing_edges = 1 that defines the number of output options from your node. You only need a higher number here if you have a decision node (see below).\n",
        "\n",
        "Here is a template for a custom node:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cZYUg4hsA8O",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from haystack import BaseComponent\n",
        "from typing import Optional, List\n",
        "\n",
        "\n",
        "class CustomNode(BaseComponent):\n",
        "    outgoing_edges = 1\n",
        "\n",
        "    def run(self, query: str, my_optional_param: Optional[int]):\n",
        "        # process the inputs\n",
        "        output = {\"my_output\": ...}\n",
        "        return output, \"output_1\"\n",
        "\n",
        "    def run_batch(self, queries: List[str], my_optional_param: Optional[int]):\n",
        "        # process the inputs\n",
        "        output = {\"my_output\": ...}\n",
        "        return output, \"output_1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "810qrYXwsA8O",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Decision Nodes\n",
        "\n",
        "Decision Nodes help you route your data so that only certain branches of your `Pipeline` are run.\n",
        "One popular use case for such query classifiers is routing keyword queries to Elasticsearch and questions to EmbeddingRetriever + Reader.\n",
        "With this approach you keep optimal speed and simplicity for keywords while going deep with transformers when it's most helpful.\n",
        "\n",
        "![image](https://github.com/deepset-ai/haystack/blob/main/docs/img/tutorial11_decision_nodes_pipeline_classifier.png?raw=true)\n",
        "\n",
        "Though this looks very similar to the ensembled pipeline shown above,\n",
        "the key difference is that only one of the retrievers is run for each request.\n",
        "By contrast both retrievers are always run in the ensembled approach.\n",
        "\n",
        "Below, we define a very naive `QueryClassifier` and show how to use it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzHCRC0ksA8O",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class CustomQueryClassifier(BaseComponent):\n",
        "    outgoing_edges = 2\n",
        "\n",
        "    def run(self, query: str):\n",
        "        if \"?\" in query:\n",
        "            return {}, \"output_2\"\n",
        "        else:\n",
        "            return {}, \"output_1\"\n",
        "\n",
        "    def run_batch(self, queries: List[str]):\n",
        "        split = {\"output_1\": {\"queries\": []}, \"output_2\": {\"queries\": []}}\n",
        "        for query in queries:\n",
        "            if \"?\" in query:\n",
        "                split[\"output_2\"][\"queries\"].append(query)\n",
        "            else:\n",
        "                split[\"output_1\"][\"queries\"].append(query)\n",
        "\n",
        "        return split, \"split\"\n",
        "\n",
        "\n",
        "# Here we build the pipeline\n",
        "p_classifier = Pipeline()\n",
        "p_classifier.add_node(component=CustomQueryClassifier(), name=\"QueryClassifier\", inputs=[\"Query\"])\n",
        "p_classifier.add_node(component=bm25_retriever, name=\"BM25Retriever\", inputs=[\"QueryClassifier.output_1\"])\n",
        "p_classifier.add_node(component=embedding_retriever, name=\"EmbeddingRetriever\", inputs=[\"QueryClassifier.output_2\"])\n",
        "p_classifier.add_node(component=reader, name=\"QAReader\", inputs=[\"BM25Retriever\", \"EmbeddingRetriever\"])\n",
        "# Uncomment the following to generate the pipeline image\n",
        "# p_classifier.draw(\"pipeline_classifier.png\")\n",
        "\n",
        "# Run only the dense retriever on the full sentence query\n",
        "res_1 = p_classifier.run(query=\"Who is the father of Arya Stark?\")\n",
        "print(\"Embedding Retriever Results\" + \"\\n\" + \"=\" * 15)\n",
        "print_answers(res_1)\n",
        "\n",
        "# Run only the sparse retriever on a keyword based query\n",
        "res_2 = p_classifier.run(query=\"Arya Stark father\")\n",
        "print(\"BM25Retriever Results\" + \"\\n\" + \"=\" * 15)\n",
        "print_answers(res_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "KhsZ_vZqsA8O",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Evaluation Nodes\n",
        "\n",
        "We have also designed a set of nodes that can be used to evaluate the performance of a system.\n",
        "Have a look at our [tutorial](https://haystack.deepset.ai/tutorials/05_evaluation) to get hands on with the code and learn more about Evaluation Nodes!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "D7d-L6A3sA8O",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Debugging Pipelines\n",
        "\n",
        "You can print out debug information from nodes in your pipelines in a few different ways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZakI7jn9sA8O",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# 1) You can set the `debug` attribute of a given node.\n",
        "bm25_retriever.debug = True\n",
        "\n",
        "# 2) You can provide `debug` as a parameter when running your pipeline\n",
        "result = p_classifier.run(query=\"Who is the father of Arya Stark?\", params={\"BM25Retriever\": {\"debug\": True}})\n",
        "\n",
        "# 3) You can provide the `debug` paramter to all nodes in your pipeline\n",
        "result = p_classifier.run(query=\"Who is the father of Arya Stark?\", params={\"debug\": True})\n",
        "\n",
        "result[\"_debug\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "VSTHlO55sA8S",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "The possibilities are endless with the `Pipeline` class and we hope that this tutorial will inspire you\n",
        "to build custom pipelines that really work for your use case!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}